{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune CNN for Cats-Dogs Classification\n",
    "### Fine-tune VGG16 top layers (conv block 5) and top-level fully connected classifier to classify images of cats and dogs.  \n",
    "#### Adapted from fchollet/classifier_from_little_data_script_3.py (https://gist.github.com/fchollet/7eb39b44eb9e16e59632d25fb3119975) and blog https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (tf.__version__)\n",
    "print (keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging level\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random generator seed\n",
    "\n",
    "seed = 123\n",
    "\n",
    "# Set python built-in random generator\n",
    "import random                             \n",
    "random.seed(seed)\n",
    "\n",
    "# Set numpy random generator\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set tensorflow random generator\n",
    "tf.random.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set location, number, and dimensions of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_width, img_height = <<FILL-IN>>, <<FILL-IN>>\n",
    "\n",
    "# Location of images\n",
    "train_data_dir = <<FILL-IN>>\n",
    "validation_data_dir = <<FILL-IN>>\n",
    "\n",
    "# Number of images\n",
    "nb_train_samples = <<FILL-IN>>\n",
    "nb_validation_samples = <<FILL-IN>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 network's imagenet weights, not including last fully connected block\n",
    "base_model = applications.VGG16 (weights='imagenet', include_top=False, \n",
    "                            input_shape=(img_width,img_height,3))\n",
    "print ('Model loaded')\n",
    "<<FILL-IN>>        # Print out base model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create top model\n",
    "#### Create top model to put on top of pre-trained CNN, and load top model's weights (generated from features notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fully connected layer as top model for CNN base\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))  # Convert 3D feature maps to 1D feature vectors\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Load classifier's weights\n",
    "top_model_weights = 'features_model_wts_saved.h5'\n",
    "top_model.load_weights (top_model_weights)\n",
    "\n",
    "# Add classifier on top of CNN base\n",
    "# model.add (top_model)\n",
    "model = Model (inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "\n",
    "# Freeze weights in CNN up to last Conv block\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = <<FILL-IN>>   # Set to False to freeze weights\n",
    "\n",
    "# Compile model with SGD optimizer with momentum and very slow learning rate\n",
    "model.compile(optimizer=optimizers.SGD (lr=1e-4, momentum=0.9),\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "<<FILL-IN>>                         # Print out model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size to 16\n",
    "<<FILL-IN>>\n",
    "\n",
    "# Data augmentation setup\n",
    "train_datagen = ImageDataGenerator (\n",
    "    rescale = 1. / 255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2, \n",
    "    horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator (\n",
    "    rescale = 1. / 255)\n",
    "\n",
    "# Set up generator to read images found in subfolders of training data directory,\n",
    "# and indefinitely generate batches of image data (scaled).  This is for training data.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=<<FILL-IN>>,   # Set to batch size defined above\n",
    "    class_mode='binary',    \n",
    "    seed=seed)              \n",
    "\n",
    "# Set up generator to generate batched of validation data for model\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    seed=seed,\n",
    "    shuffle=False)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get classification results before fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate_generator(train_generator, steps=nb_train_samples // batch_size)\n",
    "print (results)\n",
    "results = model.evaluate_generator(validation_generator, steps=nb_validation_samples // batch_size)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of training epochs\n",
    "<<FILL-IN>>\n",
    "\n",
    "# Train model, keeping track of history\n",
    "from keras.callbacks import History\n",
    "hist = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = <<FILL-IN>>,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size,\n",
    "    initial_epoch=0,\n",
    "    verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get classification results after fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model.evaluate_generator(<<FILL-IN>>, steps=nb_train_samples // batch_size)\n",
    "print (results)\n",
    "results = model.evaluate_generator(<<FILL-IN>>, steps=nb_validation_samples // batch_size)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model & weights to HDF5 file\n",
    "model_file = <<FILL-IN>> \n",
    "model.save(model_file + '.h5')\n",
    "\n",
    "# Save model to JSON file & weights to HDF5 file\n",
    "model_json = model.to_json()\n",
    "with open(model_file + '.json','w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(model_file+'-wts.h5')\n",
    "\n",
    "# Get results on validation set.  Use evaluate_generator() to get results.\n",
    "print (model.metrics_names)\n",
    "results = model.<<FILL-IN>>(validation_generator, steps=nb_validation_samples // batch_size)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load model again and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.load_model(model_file+'.h5')\n",
    "\n",
    "print (model2.metrics_names)\n",
    "results = model.evaluate_generator(validation_generator, steps=nb_validation_samples // batch_size)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (hist.<<FILL-IN>>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "result = hist.history\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(result['acc'])\n",
    "plt.plot(result['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict class of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "img_file = 'data/validation/cats/cat.1000.jpg'\n",
    "img = load_img(img_file,target_size=(150,150))\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "x = img_to_array(img) / 255\n",
    "x = np.expand_dims(x,axis=0)   # Change from (150,150,3) to (1,150,150,3)\n",
    "\n",
    "# Use model to predict class of image\n",
    "result = model.predict(x)\n",
    "print (\"Prediction probability: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = 'data/validation/dogs/dog.1150.jpg'\n",
    "img = load_img(img_file,target_size=(150,150))\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "x = img_to_array(img) / 255\n",
    "x = np.expand_dims(x,axis=0)\n",
    "\n",
    "# Use model to predict class of image\n",
    "result = <<FILL-IN>>\n",
    "print (\"Prediction probability: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = 'data/validation/dogs/dog.1200.jpg'\n",
    "img = load_img(img_file,target_size=(150,150))\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "x = img_to_array(img) / 255\n",
    "x = np.expand_dims(x,axis=0)\n",
    "\n",
    "# Use model to predict class of image\n",
    "result = model.predict(x)\n",
    "print (\"Prediction probability: \", <<FILL-IN>>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
