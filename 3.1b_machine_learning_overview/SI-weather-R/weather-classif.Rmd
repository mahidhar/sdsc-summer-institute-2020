---
title: "Classifying Weather Data"
author: "SDSC Summer Institute"
modified: "2020-08-04"
date: "`r Sys.time()`"
output:
  html_document: 
    toc: yes
  pdf_document:
    toc: yes
---

### Read Data
#### Read in weather data
```{r getData}
df <- readRDS("weather-orig.rds")
dim(df)
<<FILL-IN>>         # Print out first few rows of data
<<FILL-IN>>         # Print out last few rows of data
```

#### Remove variable RISK_MM, which is the same as Rainfall for the next day
```{r  removeRiskMM}
df$RISK_MM <- NULL
dim(df)           # Get dimensions of dataframe
names(df)
```

### Partition Data
#### Divide data into train and test sets
```{r partition}
# Randomly select 70% of samples from dataset
# Note:  'sample' was changed in R 3.6.  sample.kind setting is needed to have
#        console and knit get same sampling results
set.seed(13579, sample.kind="Rounding")
pct.trn <- 0.7                    # % of data used for training
nrows <- nrow(df)
index <- sample(1:nrows, size = pct.trn * nrows)

# Divide data into train and test sets
df.trn <- df[index,] 
df.tst <- df[-index,]
```

```{r}
# Statistics on train & test sets
dim(<<FILL-IN>>)         # Get dimensions of TRAIN set
table(df.trn$RainTomorrow)/nrow(df.trn)

<<FILL-IN>>              # Get dimensions of TEST set
table(df.tst$RainTomorrow)/nrow(df.tst)
```

```{r}
head(df.tst,3)
head(df.trn,3)
```

```{r}
# Save datasets. 
# write.csv(df.trn, "weather-trn.csv",row.names=FALSE)  # Save as CSV files
# write.csv(df.tst, "weather-tst.csv",row.names=FALSE)
saveRDS(df.trn, "weather-trn.rds")                      # Save as RDS files
saveRDS(df.tst, "weather-tst.rds")
```


### Classification using Decision Tree
#### Train model to predict whether it will rain tomorrow
```{r tree}
# install.packages("rpart"")
# install.packages("rpart.plot"")
library(rpart)
library(rpart.plot)             

# Remove variables not useful for classification (Date, Location, RainToday)
df.trn <- subset(df.trn,select=-c(Date,Location,RainToday))
df.tst <- subset(df.tst,select=-c(Date,Location,RainToday))      
```

```{r}
# Columns in datasets after removing some variables
names(df.trn)  

# Dimensions of datasets after removing some variablesdim(df.trn)
dim(df.tst)
```

```{r}
# Set seed for x-val
set.seed(567)   

# Build tree with training data.  
# Target variable is RainTomorrow, and input variables 
# are the rest of the variables.
tree.model <- rpart (RainTomorrow ~ .,data=<<FILL-IN>>, method="class")
```

```{r}
printcp(tree.model)          # Print summary of trained model
rpart.plot(tree.model)       # Plot resulting tree model
```

```{r evalTrain}
# Prediction error on train data (i.e., resubstition error)
pred.trn <- predict(tree.model,newdata=df.trn,type="class")

# Confusion matrix
table(actual=df.trn$RainTomorrow,predicted=pred.trn)

# Misclassification error on train data
err <- (1 - (sum(pred.trn==df.trn$RainTomorrow)) / nrow(df.trn))   
paste("Error on TRAIN Data: ", err)
```

```{r evalTest}
# Prediction error on test data
pred.tst <- predict(tree.model,newdata=<<FILL-IN>>,type="class")

# Confusion matrix
table(actual=df.tst$RainTomorrow,predicted=pred.tst)

# Misclassification error on test data
err <- (1 - (sum(pred.tst==df.tst$RainTomorrow)) / nrow(df.tst))
paste("Error on TEST Data: ", err)
```

#### Prune tree
```{r pruneTree}
# Get min complexity parameter value from tree
cp.best <- tree.model$cptable[which.min(tree.model$cptable[,"xerror"]),"CP"]

# Set CP criterion for pruning tree
tree.pruned <- prune(tree.model, cp=cp.best)
```

```{r}
# Summary of pruned tree
printcp(tree.pruned) 

# Plot pruned tree
rpart.plot(tree.pruned)
```

```{r}
# Apply tree to test data
pred.tst.pruned <- predict(tree.pruned,newdata=df.tst,type="class")
table(actual=df.tst$RainTomorrow,predicted=pred.tst.pruned)        
err <- (1 - (sum(pred.tst.pruned==df.tst$RainTomorrow)) / nrow(df.tst))   # Misclassification Error
paste("Error on TEST Data (Pruned Tree): ", err)
```

### Classification using Random Forest
#### Build random forest model
```{r rf}
# install.packages("randomForest")
library(randomForest)

# Build random forest from training data.
# Target variable is RainTomorrow, and input variables 
# are the rest of the variables.
# Missing values are imputed.  Importance of variables are calculated.
set.seed(765)          # For reproducibility
rf.model <- randomForest (<<FILL-IN>> ~ .,data=df.trn, na.action=na.roughfix, importance=TRUE)
print(rf.model)
```

```{r varImp}
# Variable importance
importance(rf.model)
varImpPlot(rf.model)
```

#### Evaluate random forest
```{r rftest}
# Evaluate RF model on test dataset
rf.pred.tst <- predict(rf.model,newdata=df.tst)  
table(actual=df.tst$RainTomorrow,predicted=rf.pred.tst)            
err <- (1 - (sum(rf.pred.tst==df.tst$RainTomorrow, na.rm=TRUE)) / 
          sum(complete.cases(df.tst)))                             
paste("RF Error on TEST Data: ", err)
```

